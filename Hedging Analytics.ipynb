{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('Raw_Data.xlsx', sheet_name = 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose years to remove\n",
    "start_year = 1995\n",
    "end_year = 1999\n",
    "\n",
    "omit_years = list(range(start_year,end_year,1))\n",
    "for year in omit_years:\n",
    "    data = data[data.year != year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PB ratio strategy\n",
    "\n",
    "#list of dataframes to output to excel\n",
    "final_dataframes = []\n",
    "\n",
    "#group data by year\n",
    "grouped = data.groupby(['year'])\n",
    "\n",
    "#set up dictionaries to contain highest and lowest PBs\n",
    "lowest_PB_returns = {}\n",
    "highest_PB_returns = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    #calculate percentiles of each PB relative to its group\n",
    "    group['PB_percentile'] = group['PB'].rank(pct = True)\n",
    "\n",
    "    #find bottom 10 percentile PB firms\n",
    "    lowest_PB = group.loc[group['PB_percentile'] < 0.1]\n",
    "\n",
    "    #calculate and store mean return of lowest PB in dictionary with the date as key\n",
    "    lowest_PB_returns[name]=lowest_PB['ret'].mean()\n",
    "\n",
    "    #find top 10 percentile PB firms\n",
    "    highest_PB = group.loc[group['PB_percentile'] > 0.9]\n",
    "\n",
    "    #calculate and store mean return of lowest PB in dictionary with the date as key\n",
    "    highest_PB_returns[name]=highest_PB['ret'].mean()\n",
    "\n",
    "#convert dictionaries to dataframes\n",
    "dfl = pd.DataFrame.from_dict(lowest_PB_returns, orient = 'index', columns= ['avg_ret_LPB'])    \n",
    "dfh = pd.DataFrame.from_dict(highest_PB_returns, orient = 'index', columns = ['avg_ret_HPB'])\n",
    "\n",
    "#merge dataframes\n",
    "df_pb = pd.concat([dfl,dfh], axis = 1)\n",
    "\n",
    "#calculate hedged portfolio return as average return of bottom 10 percentile PB minus top 10 percentile PB\n",
    "df_pb['avg_ret_hedged'] = df_pb['avg_ret_LPB']-df_pb['avg_ret_HPB']\n",
    "\n",
    "#calculate average return and its standard deviation\n",
    "df_pb_mean = df_pb.mean().to_frame(name = 'Average').T\n",
    "df_pb_std = df_pb.std().to_frame(name = 'STD').T\n",
    "\n",
    "#merge dataframes\n",
    "df_pb = pd.concat([df_pb,df_pb_mean,df_pb_std])\n",
    "\n",
    "#add dataframe to list exported to excel\n",
    "final_dataframes.append(df_pb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accruals Strategy\n",
    "\n",
    "#calculate accruals\n",
    "data['accruals'] = (data['ni']-data['oancf'])/data['at']\n",
    "\n",
    "grouped = data.groupby(['year'])\n",
    "\n",
    "#dictionaries for the accruals\n",
    "\n",
    "lowest_accruals = {}\n",
    "highest_accruals = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    group['acrl_percentiles'] = group['accruals'].rank(pct = True)\n",
    "\n",
    "    la = group.loc[group['acrl_percentiles']<0.1]\n",
    "\n",
    "    lowest_accruals[name] = la['ret'].mean()\n",
    "\n",
    "    ha = group.loc[group['acrl_percentiles']>0.9]\n",
    "\n",
    "    highest_accruals[name] = ha['ret'].mean()\n",
    "\n",
    "dfla = pd.DataFrame.from_dict(lowest_accruals, orient = 'index', columns = ['lowest accrual returns'])\n",
    "dfha = pd.DataFrame.from_dict(highest_accruals, orient = 'index', columns =['highest accrual returns'])\n",
    "\n",
    "dfa = pd.concat([dfla,dfha],axis = 1)\n",
    "\n",
    "#calculate hedged portfolio returns\n",
    "dfa['hedged_returns'] = dfha['highest accrual returns'] - dfla['lowest accrual returns']\n",
    "\n",
    "dfa_mean = dfa.mean().to_frame(name = 'Average').T\n",
    "dfa_std = dfa.std().to_frame(name = 'STD').T\n",
    "\n",
    "dfa = pd.concat([dfa,dfa_mean,dfa_std])\n",
    "\n",
    "final_dataframes.append(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capex to revenue signal\n",
    "\n",
    "data['capx_to_revenue'] = data['capx']/data['revt']\n",
    "\n",
    "grouped = data.groupby(['year'])\n",
    "\n",
    "low_ctr = {}\n",
    "high_ctr = {}\n",
    "\n",
    "for name, group, in grouped:\n",
    "    group['ctr_percentiles'] = group['capx_to_revenue'].rank(pct = True)\n",
    "\n",
    "    lowest_ctr = group.loc[group['ctr_percentiles'] < 0.1]\n",
    "\n",
    "    low_ctr[name] = lowest_ctr['ret'].mean()\n",
    "\n",
    "    highest_ctr = group.loc[group['ctr_percentiles'] > 0.9]\n",
    "\n",
    "    high_ctr[name] = highest_ctr['ret'].mean()\n",
    "\n",
    "\n",
    "dflc = pd.DataFrame.from_dict(low_ctr, orient = 'index', columns = ['lowest ctr returns'])\n",
    "dfhc = pd.DataFrame.from_dict(high_ctr, orient = 'index', columns =['highest ctr returns'])\n",
    "\n",
    "dfc = pd.concat([dflc,dfhc],axis = 1)\n",
    "\n",
    "dfc['hedged_returns'] = dfhc['highest ctr returns'] - dflc['lowest ctr returns']\n",
    "\n",
    "dfc_mean = dfc.mean().to_frame(name = 'Average').T\n",
    "dfc_std = dfc.std().to_frame(name = 'STD').T\n",
    "\n",
    "dfc = pd.concat([dfc,dfc_mean,dfc_std])\n",
    "\n",
    "final_dataframes.append(dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asset Turnover Signal\n",
    "\n",
    "data['revenue_assets'] = data['revt']/data['at']\n",
    "\n",
    "grouped = data.groupby(['year'])\n",
    "\n",
    "low_ra = {}\n",
    "high_ra = {}\n",
    "\n",
    "for name, group, in grouped:\n",
    "    group['ra_percentiles'] = group['revenue_assets'].rank(pct = True)\n",
    "\n",
    "    lowest_ra = group.loc[group['ra_percentiles'] < 0.1]\n",
    "\n",
    "    low_ra[name] = lowest_ra['ret'].mean()\n",
    "\n",
    "    highest_ra = group.loc[group['ra_percentiles'] > 0.9]\n",
    "\n",
    "    high_ra[name] = highest_ra['ret'].mean()\n",
    "\n",
    "\n",
    "dflra = pd.DataFrame.from_dict(low_ra, orient = 'index', columns = ['lowest ra returns'])\n",
    "dfhra = pd.DataFrame.from_dict(high_ra, orient = 'index', columns =['highest ra returns'])\n",
    "\n",
    "dfar = pd.concat([dflra,dfhra],axis = 1)\n",
    "\n",
    "dfar['hedged_returns'] = dfhra['highest ra returns'] - dflra['lowest ra returns']\n",
    "\n",
    "dfar_mean = dfar.mean().to_frame(name = 'Average').T\n",
    "dfar_std = dfar.std().to_frame(name = 'STD').T\n",
    "\n",
    "dfar = pd.concat([dfar,dfar_mean,dfar_std])\n",
    "\n",
    "#print(dfar)\n",
    "\n",
    "final_dataframes.append(dfar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#composite returns PB and Asset Turnover\n",
    "\n",
    "grouped = data.groupby(['year'])\n",
    "\n",
    "hcr = {}\n",
    "lcr = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    group['ra_percentiles'] = group['revenue_assets'].rank(pct = True)\n",
    "    group['pb_percentiles'] = group['PB'].rank(pct=True)\n",
    "    group['comp_sig'] = 0.5*(1-group['pb_percentiles'])+0.5*group['ra_percentiles']\n",
    "    group['comp_sig_pct'] = group['comp_sig'].rank(pct = True)\n",
    "    \n",
    "    highest_comp = group.loc[group['comp_sig_pct'] > 0.9]\n",
    "\n",
    "    hcr[name] = highest_comp['ret'].mean()\n",
    "\n",
    "    lowest_comp = group.loc[group['comp_sig_pct']<0.1]\n",
    "\n",
    "    lcr[name] = lowest_comp['ret'].mean()\n",
    "    \n",
    "dflcr = pd.DataFrame.from_dict(lcr, orient = 'index', columns = ['lowest comp returns'])\n",
    "dfhcr = pd.DataFrame.from_dict(hcr, orient = 'index', columns =['highest comp returns'])\n",
    "\n",
    "dfcr = pd.concat([dflcr,dfhcr],axis = 1)\n",
    "\n",
    "dfcr['hedged_returns'] = dfhcr['highest comp returns'] - dflcr['lowest comp returns']\n",
    "\n",
    "dfcr_mean = dfcr.mean().to_frame(name = 'Average').T\n",
    "dfcr_std = dfcr.std().to_frame(name = 'STD').T\n",
    "\n",
    "dfcr = pd.concat([dfcr,dfcr_mean,dfcr_std])\n",
    "\n",
    "final_dataframes.append(dfcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to Excel Sheets\n",
    "with pd.ExcelWriter('RSM429 Group Analytics Output.xlsx') as writer:\n",
    "    i = 1\n",
    "    for df in final_dataframes:\n",
    "        sheet_name = f'Q{i}'\n",
    "        df.to_excel(writer, sheet_name)\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b239acf2821489c398a9848859e84ce39b99d30cc4031fb37cc7461da3883639"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
